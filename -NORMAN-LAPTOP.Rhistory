RTREE_fitT <- RTREE_wkf |>
finalize_workflow(RTREE_best)|>
fit(bike_train_data)
RTREE_final <- RTREE_wkf |>
finalize_workflow(RTREE_best) |>
last_fit(bike_data_split)
BTREE_model <- bag_tree(tree_depth = integer(5), min_n = integer(10), cost_complexity = tune()) |>
set_engine("rpart") |>
set_mode("regression") |>
translate()
BTREE_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(BTREE_model)
RF_model <- rand_forest(mode = "regression", mtry = tune()) |>
set_engine("ranger", importance = "impurity")
#set_mode("regression")
RF_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(RF_model)
set.seed(222)
RF_tuned <- RF_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = 7,
metrics = metric_set(rmse))
RF_best <- select_best(RF_tuned, metric = "rmse")
RF_final <- RF_wkf |>
finalize_workflow(RF_best) |>
last_fit(bike_data_split)
RF_final |>
extract_fit_parsnip() |>
vip(num_features = 10)
rbind(MLR_final |> compute_metrics(metric_set(rmse, mae)),
LASSO_final |> compute_metrics(metric_set(rmse, mae)),
RTREE_final |> compute_metrics(metric_set(rmse, mae)),
#     BTREE_final |> compute_metrics(metric_set(rmse, mae)),
RF_final |> compute_metrics(metric_set(rmse, mae)))
final_model <- RF_wkf |>
fit(bd_sub) |>
tidy()
RF_final >|
RF_final |>
fit(bd_sub) |>
tidy()
RF_final |>
last_fit(bd_sub) |>
tidy()
final_model <- RF_wkf |>
last_fit(bd_sub) |>tidy()
help("last_fit")
help(fit)
help(train)
View(RF_best)
MLR_fitTR <- MLR_wkf |>
fit(bike_train_data)
MLR_fitTS <- MLR_wkf |>
last_fit(bike_data_split)
library(baguette)
library(readr)
library(lubridate)
library(recipes)
library(tidyverse)
library(tidymodels)
library(tree)
library(vip)
raw_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv",
locale = locale(encoding = "latin1"))
library(dplyr)
library(lubridate)
library(forcats)
bike_data <-
raw_data |>
rename(
DATE = `Date`,
RBC = `Rented Bike Count`,
HOUR = `Hour`,
"TEMP(deg C)" = `Temperature(째C)`,
"RH(%)" = `Humidity(%)`,
"WD_SPD(m/s)" = `Wind speed (m/s)`,
"VIS(10m)" = `Visibility (10m)`,
"DP_TEMP(deg C)" = `Dew point temperature(째C)`,
"SOL_RAD(MJ/m2)" = `Solar Radiation (MJ/m2)`,
"RAIN_FALL(mm)" = `Rainfall(mm)`,
"SNOW_FALL(cm)" = `Snowfall (cm)`,
SEASONS = `Seasons`,
HOLIDAY = `Holiday`,
FUNC_DAY = `Functioning Day`
) |>
mutate(
DATE = dmy(DATE),
HOLIDAY = as_factor(HOLIDAY),
SEASONS = as_factor(SEASONS),
FUNC_DAY = as_factor(FUNC_DAY)
)
write.csv(bike_data, "bike_data.csv")
bd_sub <- bike_data |>
group_by(DATE, SEASONS, HOLIDAY) |>
summarise(across(where(is.numeric) , mean, na.rm = TRUE, .names = '{col}_MEAN'),
SUM_RBC = sum(RBC),
"SUM_RAIN_FALL(mm)" = sum(`RAIN_FALL(mm)`),
"SUM_SNOW_FALL(cm)" = sum(`SNOW_FALL(cm)`),) |>
select(DATE, SEASONS, HOLIDAY, starts_with("SUM"), everything(), -RBC_MEAN, -HOUR_MEAN, -`RAIN_FALL(mm)_MEAN`, -`SNOW_FALL(cm)_MEAN`)
write.csv(bd_sub, "bd_sub_after.csv")
library(tidymodels)
set.seed(222)
# Put 3/4 of the data into the training set.  init_split is the Test Set.
bike_data_split <- initial_split(bd_sub, prop = 3/4, strata = SEASONS)
# Create data frames for the two sets:
bike_train_data <- training(bike_data_split)
bike_test_data  <- testing(bike_data_split)
#On the training set, create a 10 fold CV split
bike_CV_folds <- vfold_cv(bike_train_data, 10)
#Define Recipe 1
recipe1 <-
recipe(SUM_RBC ~ ., data = bike_train_data) |>
step_date(DATE, features = c("dow")) |>
step_mutate(
DAY_TYPE = factor(
ifelse(
DATE_dow == "Sat" | DATE_dow == "Sun", "WKEND", "WKDAY"))) |>
step_rm(DATE_dow, DATE) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
recipe1_prep <- prep(recipe1, training = bike_train_data)
recipe1_baked <- bake(recipe1_prep, new_data = bike_test_data)
write.csv(recipe1_baked, "recipe1_baked.csv")
#Define Recipe 2
recipe2 <-
recipe(SUM_RBC ~ ., data = bike_train_data) |>
step_date(DATE, features = c("dow")) |>
step_mutate(
DAY_TYPE = factor(
ifelse(
DATE_dow == "Sat" | DATE_dow == "Sun", "WKEND", "WKDAY"))) |>
step_rm(DATE_dow, DATE) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors()) |>
step_interact(
terms = ~ starts_with("HOLIDAY"):starts_with("SEASONS") +
`TEMP(deg C)_MEAN`:starts_with("SEASONS") +
`TEMP(deg C)_MEAN`:`SUM_RAIN_FALL(mm)`
)
recipe2_prep <- prep(recipe2, training = bike_train_data)
recipe2_baked <- bake(recipe2_prep, new_data = bike_test_data)
write.csv(recipe2_baked, "recipe2_baked.csv")
MLR_model <- linear_reg() |>
set_engine("lm")
MLR_wkf <- workflow() |>
add_recipe(recipe2) |>
add_model(MLR_model)
set.seed(222)
MLR_CV_fit <- MLR_wkf |>
fit_resamples(bike_CV_folds)
MLR_fitT <- MLR_wkf |>
fit(bike_train_data)
MLR_final <- MLR_wkf |>
last_fit(bike_data_split)
LASSO_model <- linear_reg(penalty = tune(), mixture = 1) |>
set_engine("glmnet")
LASSO_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(LASSO_model)
set.seed(222)
LASSO_grid <- LASSO_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = grid_regular(penalty(), levels = 200))
LASSO_best <- LASSO_grid |>
select_best(metric = "rmse")
LASSO_fitT <- LASSO_wkf |>
finalize_workflow(LASSO_best) |>
fit(bike_train_data)
LASSO_final <- LASSO_wkf |>
finalize_workflow(LASSO_best) |>
last_fit(bike_data_split)
RTREE_model <- decision_tree(tree_depth = tune(),
min_n = 20,
cost_complexity = tune()) |>
set_engine("rpart") |>
set_mode("regression")
RTREE_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(RTREE_model)
set.seed(222)
RTREE_grid <- grid_regular(cost_complexity(),
tree_depth(),
levels = c(10, 5))
RTREE_fits <- RTREE_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = RTREE_grid)
RTREE_best <- select_best(RTREE_fits, metric = "rmse")
RTREE_fitT <- RTREE_wkf |>
finalize_workflow(RTREE_best)|>
fit(bike_train_data)
RTREE_final <- RTREE_wkf |>
finalize_workflow(RTREE_best) |>
last_fit(bike_data_split)
RF_model <- rand_forest(mode = "regression", mtry = tune()) |>
set_engine("ranger", importance = "impurity")
#set_mode("regression")
RF_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(RF_model)
set.seed(222)
RF_tuned <- RF_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = 7,
metrics = metric_set(rmse))
RF_best <- select_best(RF_tuned, metric = "rmse")
RF_fitT <- RF_wkf |>
finalize_workflow(RF_best)|>
fit(bike_train_data)
RF_final <- RF_wkf |>
finalize_workflow(RF_best) |>
last_fit(bike_data_split)
rbind(MLR_final |> compute_metrics(metric_set(rmse, mae)),
LASSO_final |> compute_metrics(metric_set(rmse, mae)),
RTREE_final |> compute_metrics(metric_set(rmse, mae)),
#     BTREE_final |> compute_metrics(metric_set(rmse, mae)),
RF_final |> compute_metrics(metric_set(rmse, mae)))
MLR_final |>
extract_fit_parsnip() |>
tidy()
LASSO_final |>
extract_fit_engine() |>
tidy() |>
rename(penalty = lambda) |>   # <- for consistent naming
filter(term != "(Intercept)")
RTREE_final |>
extract_fit_engine() |>
rpart.plot::rpart.plot(roundint = FALSE)
RF_final |>
extract_fit_parsnip() |>
vip(num_features = 10)
RF_final
RF_fot <- RF_final |>
extract_fit_parsnip() |>
vip(num_features = 10)
RF_fot
RF_final |>
extract_fit_parsnip() |>
vip(num_features = 10)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bike_data)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bd_sub)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bd_sub)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bd_sub) |>
extract_fit_parsnip() |>
vip(num_features = 10)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bd_sub) |>
extract_fit_parsnip() |>
vip(num_features = 10)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bd_sub) |>
extract_fit_parsnip() |>
vip(num_features = 10)
Final_Model
bd_sub
bd_sub
library(baguette)
library(readr)
library(lubridate)
library(recipes)
library(tidyverse)
library(tidymodels)
library(tree)
library(vip)
raw_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv",
locale = locale(encoding = "latin1"))
library(dplyr)
library(lubridate)
library(forcats)
bike_data <-
raw_data |>
rename(
DATE = `Date`,
RBC = `Rented Bike Count`,
HOUR = `Hour`,
"TEMP(deg C)" = `Temperature(째C)`,
"RH(%)" = `Humidity(%)`,
"WD_SPD(m/s)" = `Wind speed (m/s)`,
"VIS(10m)" = `Visibility (10m)`,
"DP_TEMP(deg C)" = `Dew point temperature(째C)`,
"SOL_RAD(MJ/m2)" = `Solar Radiation (MJ/m2)`,
"RAIN_FALL(mm)" = `Rainfall(mm)`,
"SNOW_FALL(cm)" = `Snowfall (cm)`,
SEASONS = `Seasons`,
HOLIDAY = `Holiday`,
FUNC_DAY = `Functioning Day`
) |>
mutate(
DATE = dmy(DATE),
HOLIDAY = as_factor(HOLIDAY),
SEASONS = as_factor(SEASONS),
FUNC_DAY = as_factor(FUNC_DAY)
)
write.csv(bike_data, "bike_data.csv")
bd_sub <- bike_data |>
group_by(DATE, SEASONS, HOLIDAY) |>
summarise(across(where(is.numeric) , mean, na.rm = TRUE, .names = '{col}_MEAN'),
SUM_RBC = sum(RBC),
"SUM_RAIN_FALL(mm)" = sum(`RAIN_FALL(mm)`),
"SUM_SNOW_FALL(cm)" = sum(`SNOW_FALL(cm)`),) |>
select(DATE, SEASONS, HOLIDAY, starts_with("SUM"), everything(), -RBC_MEAN, -HOUR_MEAN, -`RAIN_FALL(mm)_MEAN`, -`SNOW_FALL(cm)_MEAN`)
write.csv(bd_sub, "bd_sub_after.csv")
library(tidymodels)
set.seed(222)
# Put 3/4 of the data into the training set.  init_split is the Test Set.
bike_data_split <- initial_split(bd_sub, prop = 3/4, strata = SEASONS)
# Create data frames for the two sets:
bike_train_data <- training(bike_data_split)
bike_test_data  <- testing(bike_data_split)
#On the training set, create a 10 fold CV split
bike_CV_folds <- vfold_cv(bike_train_data, 10)
#Define Recipe 1
recipe1 <-
recipe(SUM_RBC ~ ., data = bike_train_data) |>
step_date(DATE, features = c("dow")) |>
step_mutate(
DAY_TYPE = factor(
ifelse(
DATE_dow == "Sat" | DATE_dow == "Sun", "WKEND", "WKDAY"))) |>
step_rm(DATE_dow, DATE) |>
step_normalize(all_numeric_predictors()) |>
#  step_dummy(all_nominal_predictors())
step_dummy(SEASONS, HOLIDAY, DAY_TYPE)
recipe1_prep <- prep(recipe1, training = bike_train_data)
recipe1_baked <- bake(recipe1_prep, new_data = bike_test_data)
write.csv(recipe1_baked, "recipe1_baked.csv")
#Define Recipe 2
recipe2 <-
recipe(SUM_RBC ~ ., data = bike_train_data) |>
step_date(DATE, features = c("dow")) |>
step_mutate(
DAY_TYPE = factor(
ifelse(
DATE_dow == "Sat" | DATE_dow == "Sun", "WKEND", "WKDAY"))) |>
step_rm(DATE_dow, DATE) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors()) |>
step_interact(
terms = ~ starts_with("HOLIDAY"):starts_with("SEASONS") +
`TEMP(deg C)_MEAN`:starts_with("SEASONS") +
`TEMP(deg C)_MEAN`:`SUM_RAIN_FALL(mm)`
)
recipe2_prep <- prep(recipe2, training = bike_train_data)
recipe2_baked <- bake(recipe2_prep, new_data = bike_test_data)
write.csv(recipe2_baked, "recipe2_baked.csv")
MLR_model <- linear_reg() |>
set_engine("lm")
MLR_wkf <- workflow() |>
add_recipe(recipe2) |>
add_model(MLR_model)
MLR_CV_fit <- MLR_wkf |>
fit_resamples(bike_CV_folds)
MLR_fitT <- MLR_wkf |>
fit(bike_train_data)
MLR_final <- MLR_wkf |>
last_fit(bike_data_split)
LASSO_model <- linear_reg(penalty = tune(), mixture = 1) |>
set_engine("glmnet")
LASSO_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(LASSO_model)
LASSO_grid <- LASSO_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = grid_regular(penalty(), levels = 200))
LASSO_best <- LASSO_grid |>
select_best(metric = "rmse")
LASSO_fitT <- LASSO_wkf |>
finalize_workflow(LASSO_best) |>
fit(bike_train_data)
LASSO_final <- LASSO_wkf |>
finalize_workflow(LASSO_best) |>
last_fit(bike_data_split)
RTREE_model <- decision_tree(tree_depth = tune(),
min_n = 20,
cost_complexity = tune()) |>
set_engine("rpart") |>
set_mode("regression")
RTREE_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(RTREE_model)
RTREE_grid <- grid_regular(cost_complexity(),
tree_depth(),
levels = c(10, 5))
RTREE_fits <- RTREE_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = RTREE_grid)
RTREE_best <- select_best(RTREE_fits, metric = "rmse")
RTREE_fitT <- RTREE_wkf |>
finalize_workflow(RTREE_best)|>
fit(bike_train_data)
RTREE_final <- RTREE_wkf |>
finalize_workflow(RTREE_best) |>
last_fit(bike_data_split)
BTREE_model <- bag_tree(tree_depth = integer(5), min_n = integer(10), cost_complexity = tune()) |>
set_engine("rpart") |>
set_mode("regression") |>
translate()
BTREE_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(BTREE_model)
BTREE_tuned <- BTREE_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = grid_regular(cost_complexity(),
levels = 15),
metrics = metric_set(rmse))
RF_model <- rand_forest(mode = "regression", mtry = tune()) |>
set_engine("ranger", importance = "impurity")
#set_mode("regression")
RF_wkf <- workflow() |>
add_recipe(recipe1) |>
add_model(RF_model)
RF_tuned <- RF_wkf |>
tune_grid(resamples = bike_CV_folds,
grid = 7,
metrics = metric_set(rmse))
RF_best <- select_best(RF_tuned, metric = "rmse")
RF_fitT <- RF_wkf |>
finalize_workflow(RF_best)|>
fit(bike_train_data)
RF_final <- RF_wkf |>
finalize_workflow(RF_best) |>
last_fit(bike_data_split)
rbind(MLR_final |> compute_metrics(metric_set(rmse, mae)),
LASSO_final |> compute_metrics(metric_set(rmse, mae)),
RTREE_final |> compute_metrics(metric_set(rmse, mae)),
#     BTREE_final |> compute_metrics(metric_set(rmse, mae)),
RF_final |> compute_metrics(metric_set(rmse, mae)))
MLR_final |>
extract_fit_parsnip() |>
tidy()
LASSO_final |>
extract_fit_engine() |>
tidy() |>
rename(penalty = lambda) |>   # <- for consistent naming
filter(term != "(Intercept)")
RTREE_final |>
extract_fit_engine() |>
rpart.plot::rpart.plot(roundint = FALSE)
RF_final |>
extract_fit_parsnip() |>
vip(num_features = 10)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bd_sub) |>
extract_fit_parsnip() |>
vip(num_features = 10)
Final_Model
#Define Recipe 1
recipe1 <-
recipe(SUM_RBC ~ ., data = bike_train_data) |>
step_date(DATE, features = c("dow")) |>
step_mutate(
DAY_TYPE = factor(
ifelse(
DATE_dow == "Sat" | DATE_dow == "Sun", "WKEND", "WKDAY"))) |>
step_rm(DATE_dow, DATE) |>
step_normalize(all_numeric_predictors()) |>
#  step_dummy(all_nominal_predictors())
step_dummy(SEASONS, HOLIDAY, DAY_TYPE)
recipe1_prep <- prep(recipe1, training = bike_train_data)
recipe1_baked <- bake(recipe1_prep, new_data = bike_test_data)
write.csv(recipe1_baked, "recipe1_baked.csv")
View(recipe1_baked)
View(recipe1_baked)
LASSO_final |>
extract_fit_parsnip() |>
tidy()
# rename(penalty = lambda) |>   # <- for consistent naming
# filter(term != "(Intercept)")
RTREE_final |>
extract_fit_engine() |>
rpart.plot::rpart.plot(roundint = FALSE)
RTREE_final |>
extract_fit_engine() |>
rpart.plot::rpart.plot(cex = 3 , roundint = FALSE)
RTREE_final |>
extract_fit_engine() |>
rpart.plot::rpart.plot(cex = 3 , roundint = FALSE)
RTREE_final |>
extract_fit_engine() |>
rpart.plot::rpart.plot(cex = 1 , roundint = FALSE)
RTREE_final |>
extract_fit_engine() |>
rpart.plot::rpart.plot(cex = 0.5 , roundint = FALSE)
Final_Model <- RF_wkf |>
finalize_workflow(RF_best) |>
fit(bd_sub) |>
extract_fit_parsnip() |>
vip(num_features = 10)
Final_Model
unlink("_cache", recursive = TRUE)
library(baguette)
library(readr)
library(lubridate)
library(recipes)
library(tidyverse)
library(tidymodels)
library(tree)
library(vip)
raw_data <- read_csv("https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv",
locale = locale(encoding = "latin1"))
